{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-28T10:33:09.031153Z",
     "start_time": "2024-06-28T10:33:06.135236Z"
    }
   },
   "source": [
    "import dianna\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import onnxruntime as ort"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "99fd69f722da7f4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:33:09.073685Z",
     "start_time": "2024-06-28T10:33:09.032055Z"
    }
   },
   "source": [
    "transform = transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "39020461ca21ff92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:33:09.076881Z",
     "start_time": "2024-06-28T10:33:09.074642Z"
    }
   },
   "source": [
    "model_path = \"./models/mnist_model.onnx\" # an onnx model containing a cNN for the binary-mnist, aka. classifying as 0 or 1\n",
    "axis_labels = {0: 'channels'}"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:33:09.080784Z",
     "start_time": "2024-06-28T10:33:09.078669Z"
    }
   },
   "cell_type": "code",
   "source": "return_training_tensors_from_target_class = lambda target: trainset.data[trainset.targets == target]",
   "id": "c180cf92c4a2b9dc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:33:09.090365Z",
     "start_time": "2024-06-28T10:33:09.081267Z"
    }
   },
   "cell_type": "code",
   "source": "first_zero = return_training_tensors_from_target_class(0)[0]",
   "id": "7067dca89cd66442",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:33:09.222804Z",
     "start_time": "2024-06-28T10:33:09.091305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the first zero as reference\n",
    "plt.imshow(first_zero, cmap=\"grey\")"
   ],
   "id": "5d75082131759c9d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14009e850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaiElEQVR4nO3de2xT5/3H8Y+h4AJNLGWQ2BkhiirQpkJhXMpFlJtERLYiKN0EdCrhH0THRWVph8agI5smUqGCui2Dbd3GQIWBtFLKVFaaKSSwUaaUi4pYhUCEkYpkGRGzQ6BGwPP7A+FfTULgGJtv7Lxf0iPhc86X883hIZ88sX3sc845AQBgoId1AwCA7osQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgJnHrBu4261bt3Tx4kVlZWXJ5/NZtwMA8Mg5p9bWVuXn56tHj87XOl0uhC5evKiCggLrNgAAD6mhoUEDBw7s9Jgu9+u4rKws6xYAAEnwIN/PUxZCmzZtUlFRkR5//HGNGjVKhw4deqA6fgUHAJnhQb6fpySEdu3apRUrVmj16tU6fvy4nn32WZWUlOjChQupOB0AIE35UnEX7bFjx2rkyJHavHlzbNvXv/51zZ49WxUVFZ3WRiIRBQKBZLcEAHjEwuGwsrOzOz0m6Suh69ev6+jRoyouLo7bXlxcrMOHD7c7PhqNKhKJxA0AQPeQ9BC6dOmSbt68qby8vLjteXl5ampqand8RUWFAoFAbPDKOADoPlL2woS7n5ByznX4JNWqVasUDodjo6GhIVUtAQC6mKS/T6h///7q2bNnu1VPc3Nzu9WRJPn9fvn9/mS3AQBIA0lfCfXu3VujRo1SVVVV3PaqqipNmDAh2acDAKSxlNwxoaysTC+99JJGjx6t8ePH67e//a0uXLigl19+ORWnAwCkqZSE0Ny5c9XS0qKf/vSnamxs1NChQ7Vv3z4VFham4nQAgDSVkvcJPQzeJwQAmcHkfUIAADwoQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYecy6AQAPZtSoUZ5rli1bltC5FixY4Llm27Ztnmt++ctfeq45duyY5xp0XayEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmPE555x1E18WiUQUCASs2wBSasSIEZ5rqqurPddkZ2d7rnmUwuGw55qvfOUrKegEqRAOh+87B1kJAQDMEEIAADNJD6Hy8nL5fL64EQwGk30aAEAGSMmH2j311FP629/+Fnvcs2fPVJwGAJDmUhJCjz32GKsfAMB9peQ5oTNnzig/P19FRUWaN2+ezp07d89jo9GoIpFI3AAAdA9JD6GxY8dq27Zt2r9/v95++201NTVpwoQJamlp6fD4iooKBQKB2CgoKEh2SwCALirl7xNqa2vTk08+qZUrV6qsrKzd/mg0qmg0GnsciUQIImQ83id0G+8TymwP8j6hlDwn9GX9+vXTsGHDdObMmQ73+/1++f3+VLcBAOiCUv4+oWg0qs8++0yhUCjVpwIApJmkh9Brr72m2tpa1dfX65///Ke+/e1vKxKJqLS0NNmnAgCkuaT/Ou7zzz/X/PnzdenSJQ0YMEDjxo3TkSNHVFhYmOxTAQDSHDcwBR7SM88847nm3Xff9VyTn5/vuSbR/96tra2ea65fv+65JpEXGUycONFzzbFjxzzXSIl9Tfh/3MAUANClEUIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMJPyD7UDLPTt2zehupEjR3queeeddzzXdPXP17rXh1B2Zv369Z5rdu7c6bnmH//4h+eaNWvWeK6RpIqKioTq8OBYCQEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzHAXbWSk3/zmNwnVzZ8/P8mdpKdE7ib+xBNPeK6pra31XDNlyhTPNU8//bTnGjwarIQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCY4Qam6PJGjRrlueZb3/pWQufy+XwJ1XmVyI07//KXv3iuefPNNz3XSNLFixc91xw/ftxzzeXLlz3XTJs2zXPNo/p3hXeshAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJjxOeecdRNfFolEFAgErNtAiowYMcJzTXV1teea7OxszzWJ+utf/+q5Zv78+Z5rJk+e7Lnm6aef9lwjSb/73e881/z3v/9N6Fxe3bx503PN1atXEzpXItf82LFjCZ0rE4XD4fv+X2QlBAAwQwgBAMx4DqGDBw9q5syZys/Pl8/n0549e+L2O+dUXl6u/Px89enTR1OmTNGpU6eS1S8AIIN4DqG2tjYNHz5clZWVHe5fv369Nm7cqMrKStXV1SkYDGr69OlqbW196GYBAJnF8yerlpSUqKSkpMN9zjm99dZbWr16tebMmSNJ2rp1q/Ly8rRjxw4tXrz44boFAGSUpD4nVF9fr6amJhUXF8e2+f1+TZ48WYcPH+6wJhqNKhKJxA0AQPeQ1BBqamqSJOXl5cVtz8vLi+27W0VFhQKBQGwUFBQksyUAQBeWklfH+Xy+uMfOuXbb7li1apXC4XBsNDQ0pKIlAEAX5Pk5oc4Eg0FJt1dEoVAotr25ubnd6ugOv98vv9+fzDYAAGkiqSuhoqIiBYNBVVVVxbZdv35dtbW1mjBhQjJPBQDIAJ5XQleuXNHZs2djj+vr63XixAnl5ORo0KBBWrFihdatW6fBgwdr8ODBWrdunfr27asXX3wxqY0DANKf5xD65JNPNHXq1NjjsrIySVJpaan++Mc/auXKlbp27ZqWLFmiy5cva+zYsfroo4+UlZWVvK4BABmBG5giYUOGDPFcs3btWs818+bN81xz6dIlzzWS1NjY6LnmZz/7meeaP//5z55rcFsiNzBN9Nvcrl27PNd897vfTehcmYgbmAIAujRCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgJmkfrIq0lOin2z75ptveq755je/6bmmtbXVc82CBQs810i3P6rEqz59+iR0LnR9gwYNsm4h47ESAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYbmELf+MY3EqpL5GakiZg1a5bnmtra2hR0AiDZWAkBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwww1MoY0bNyZU5/P5PNckcmNRbkaKL+vRw/vPzrdu3UpBJ0gGVkIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMcAPTDPPcc895rhkxYkRC53LOea7Zu3dvQucC7kjkZqSJzFVJOnHiREJ1eHCshAAAZgghAIAZzyF08OBBzZw5U/n5+fL5fNqzZ0/c/oULF8rn88WNcePGJatfAEAG8RxCbW1tGj58uCorK+95zIwZM9TY2Bgb+/bte6gmAQCZyfMLE0pKSlRSUtLpMX6/X8FgMOGmAADdQ0qeE6qpqVFubq6GDBmiRYsWqbm5+Z7HRqNRRSKRuAEA6B6SHkIlJSXavn27qqurtWHDBtXV1WnatGmKRqMdHl9RUaFAIBAbBQUFyW4JANBFJf19QnPnzo39eejQoRo9erQKCwv1wQcfaM6cOe2OX7VqlcrKymKPI5EIQQQA3UTK36waCoVUWFioM2fOdLjf7/fL7/enug0AQBeU8vcJtbS0qKGhQaFQKNWnAgCkGc8roStXrujs2bOxx/X19Tpx4oRycnKUk5Oj8vJyvfDCCwqFQjp//rx+9KMfqX///nr++eeT2jgAIP15DqFPPvlEU6dOjT2+83xOaWmpNm/erJMnT2rbtm363//+p1AopKlTp2rXrl3KyspKXtcAgIzgOYSmTJnS6c0A9+/f/1AN4eH06dPHc03v3r0TOldnL72/l127diV0LnR9iTy3W15envxGOlBdXZ1Q3apVq5LcCe7GveMAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGZS/smqyFzRaNRzTWNjYwo6QbIlckfsNWvWeK75wQ9+4Lnm888/91yzYcMGzzXS7c9PQ2qxEgIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGG5giYXv37rVuAfcxYsSIhOoSubHo3LlzPde8//77nmteeOEFzzXoulgJAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMMMNTDOMz+d7JDWSNHv2bM81r7zySkLngvT973/fc83rr7+e0LkCgYDnmu3bt3uuWbBggecaZBZWQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMxwA9MM45x7JDWSFAwGPdf84he/8Fzzhz/8wXNNS0uL5xpJGjdunOeal156yXPN8OHDPdcMHDjQc82FCxc810jS/v37Pdds2rQpoXOhe2MlBAAwQwgBAMx4CqGKigqNGTNGWVlZys3N1ezZs3X69Om4Y5xzKi8vV35+vvr06aMpU6bo1KlTSW0aAJAZPIVQbW2tli5dqiNHjqiqqko3btxQcXGx2traYsesX79eGzduVGVlperq6hQMBjV9+nS1trYmvXkAQHrz9MKEDz/8MO7xli1blJubq6NHj2rSpElyzumtt97S6tWrNWfOHEnS1q1blZeXpx07dmjx4sXJ6xwAkPYe6jmhcDgsScrJyZEk1dfXq6mpScXFxbFj/H6/Jk+erMOHD3f4d0SjUUUikbgBAOgeEg4h55zKyso0ceJEDR06VJLU1NQkScrLy4s7Ni8vL7bvbhUVFQoEArFRUFCQaEsAgDSTcAgtW7ZMn376qf70pz+12+fz+eIeO+fabbtj1apVCofDsdHQ0JBoSwCANJPQm1WXL1+uvXv36uDBg3FvoLvz5sWmpiaFQqHY9ubm5narozv8fr/8fn8ibQAA0pynlZBzTsuWLdPu3btVXV2toqKiuP1FRUUKBoOqqqqKbbt+/bpqa2s1YcKE5HQMAMgYnlZCS5cu1Y4dO/T+++8rKysr9jxPIBBQnz595PP5tGLFCq1bt06DBw/W4MGDtW7dOvXt21cvvvhiSr4AAED68hRCmzdvliRNmTIlbvuWLVu0cOFCSdLKlSt17do1LVmyRJcvX9bYsWP10UcfKSsrKykNAwAyh88levfKFIlEIgoEAtZtpK3vfOc7nms6enFJV/Kf//zHc02iL/UfPHhwQnWPwscff+y55sCBAwmd68c//nFCdcCXhcNhZWdnd3oM944DAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJhJ6JNV0XUlcqflurq6hM41ZsyYhOq8uvOJvV7c65N8U6GlpcVzzc6dOz3XvPLKK55rgK6OlRAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzPuecs27iyyKRiAKBgHUb3UooFEqobvHixZ5r1qxZ47nG5/N5rkl0Wv/85z/3XLN582bPNWfPnvVcA6SbcDis7OzsTo9hJQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMNzAFAKQENzAFAHRphBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAw4ymEKioqNGbMGGVlZSk3N1ezZ8/W6dOn445ZuHChfD5f3Bg3blxSmwYAZAZPIVRbW6ulS5fqyJEjqqqq0o0bN1RcXKy2tra442bMmKHGxsbY2LdvX1KbBgBkhse8HPzhhx/GPd6yZYtyc3N19OhRTZo0Kbbd7/crGAwmp0MAQMZ6qOeEwuGwJCknJydue01NjXJzczVkyBAtWrRIzc3N9/w7otGoIpFI3AAAdA8+55xLpNA5p1mzZuny5cs6dOhQbPuuXbv0xBNPqLCwUPX19Xr99dd148YNHT16VH6/v93fU15erp/85CeJfwUAgC4pHA4rOzu784NcgpYsWeIKCwtdQ0NDp8ddvHjR9erVy7377rsd7v/iiy9cOByOjYaGBieJwWAwGGk+wuHwfbPE03NCdyxfvlx79+7VwYMHNXDgwE6PDYVCKiws1JkzZzrc7/f7O1whAQAyn6cQcs5p+fLleu+991RTU6OioqL71rS0tKihoUGhUCjhJgEAmcnTCxOWLl2qd955Rzt27FBWVpaamprU1NSka9euSZKuXLmi1157TR9//LHOnz+vmpoazZw5U/3799fzzz+fki8AAJDGvDwPpHv83m/Lli3OOeeuXr3qiouL3YABA1yvXr3coEGDXGlpqbtw4cIDnyMcDpv/HpPBYDAYDz8e5DmhhF8dlyqRSESBQMC6DQDAQ3qQV8dx7zgAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgJkuF0LOOesWAABJ8CDfz7tcCLW2tlq3AABIggf5fu5zXWzpcevWLV28eFFZWVny+Xxx+yKRiAoKCtTQ0KDs7GyjDu1xHW7jOtzGdbiN63BbV7gOzjm1trYqPz9fPXp0vtZ57BH19MB69OihgQMHdnpMdnZ2t55kd3AdbuM63MZ1uI3rcJv1dQgEAg90XJf7dRwAoPsghAAAZtIqhPx+v9auXSu/32/diimuw21ch9u4DrdxHW5Lt+vQ5V6YAADoPtJqJQQAyCyEEADADCEEADBDCAEAzKRVCG3atElFRUV6/PHHNWrUKB06dMi6pUeqvLxcPp8vbgSDQeu2Uu7gwYOaOXOm8vPz5fP5tGfPnrj9zjmVl5crPz9fffr00ZQpU3Tq1CmbZlPoftdh4cKF7ebHuHHjbJpNkYqKCo0ZM0ZZWVnKzc3V7Nmzdfr06bhjusN8eJDrkC7zIW1CaNeuXVqxYoVWr16t48eP69lnn1VJSYkuXLhg3doj9dRTT6mxsTE2Tp48ad1SyrW1tWn48OGqrKzscP/69eu1ceNGVVZWqq6uTsFgUNOnT8+4+xDe7zpI0owZM+Lmx759+x5hh6lXW1urpUuX6siRI6qqqtKNGzdUXFystra22DHdYT48yHWQ0mQ+uDTxzDPPuJdffjlu29e+9jX3wx/+0KijR2/t2rVu+PDh1m2YkuTee++92ONbt265YDDo3njjjdi2L774wgUCAffrX//aoMNH4+7r4JxzpaWlbtasWSb9WGlubnaSXG1trXOu+86Hu6+Dc+kzH9JiJXT9+nUdPXpUxcXFcduLi4t1+PBho65snDlzRvn5+SoqKtK8efN07tw565ZM1dfXq6mpKW5u+P1+TZ48udvNDUmqqalRbm6uhgwZokWLFqm5udm6pZQKh8OSpJycHEnddz7cfR3uSIf5kBYhdOnSJd28eVN5eXlx2/Py8tTU1GTU1aM3duxYbdu2Tfv379fbb7+tpqYmTZgwQS0tLdatmbnz79/d54YklZSUaPv27aqurtaGDRtUV1enadOmKRqNWreWEs45lZWVaeLEiRo6dKik7jkfOroOUvrMhy53F+3O3P3RDs65dtsyWUlJSezPw4YN0/jx4/Xkk09q69atKisrM+zMXnefG5I0d+7c2J+HDh2q0aNHq7CwUB988IHmzJlj2FlqLFu2TJ9++qn+/ve/t9vXnebDva5DusyHtFgJ9e/fXz179mz3k0xzc3O7n3i6k379+mnYsGE6c+aMdStm7rw6kLnRXigUUmFhYUbOj+XLl2vv3r06cOBA3Ee/dLf5cK/r0JGuOh/SIoR69+6tUaNGqaqqKm57VVWVJkyYYNSVvWg0qs8++0yhUMi6FTNFRUUKBoNxc+P69euqra3t1nNDklpaWtTQ0JBR88M5p2XLlmn37t2qrq5WUVFR3P7uMh/udx060mXng+GLIjzZuXOn69Wrl/v973/v/vWvf7kVK1a4fv36ufPnz1u39si8+uqrrqamxp07d84dOXLEPffccy4rKyvjr0Fra6s7fvy4O378uJPkNm7c6I4fP+7+/e9/O+ece+ONN1wgEHC7d+92J0+edPPnz3ehUMhFIhHjzpOrs+vQ2trqXn31VXf48GFXX1/vDhw44MaPH++++tWvZtR1+N73vucCgYCrqalxjY2NsXH16tXYMd1hPtzvOqTTfEibEHLOuV/96leusLDQ9e7d240cOTLu5Yjdwdy5c10oFHK9evVy+fn5bs6cOe7UqVPWbaXcgQMHnKR2o7S01Dl3+2W5a9eudcFg0Pn9fjdp0iR38uRJ26ZToLPrcPXqVVdcXOwGDBjgevXq5QYNGuRKS0vdhQsXrNtOqo6+fkluy5YtsWO6w3y433VIp/nARzkAAMykxXNCAIDMRAgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwMz/AdDDJYtBgQkJAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h4>In this Section we generate multiple saliency maps with RISE to heuristically determine, which number of masks is viable in general</h4>\n",
    "As RISE is computionally heavy, the code is commented out. The Runtime for this cell is approximately 22 minutes (with a mac mini m2, results may vary), because of the last saliency map generation with 1 million masks. \n",
    "For the output, please refer to the \"rise_n_masks.png\" file in the images folder"
   ],
   "id": "d2afc57c74c2d8ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:33:09.226904Z",
     "start_time": "2024-06-28T10:33:09.223495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate a grid-picture with the first zero, showing saliency maps generated with RISE but with a different number of masks\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(2, 3)\n",
    "num_of_masks=[[10**1, 10**2, 10**3], [10**4, 10**5, 10**6]]\n",
    "first_zero_input = first_zero.numpy().reshape(1, 28, 28).astype(np.float32)\n",
    "for i in range(2):\n",
    "    current_masks = num_of_masks[0] if i == 0 else num_of_masks[1]\n",
    "    for j in range(3):\n",
    "        saliency_map_rise = dianna.explain_image(model_path, first_zero_input, method=\"RISE\", labels=[0], n_masks=current_masks[j], axis_labels=axis_labels, p_keep=0.5)\n",
    "        ax[i, j].set_title(f\"Masks = {current_masks[j]}\")\n",
    "        ax[i, j].imshow(saliency_map_rise.reshape(28, 28))\n",
    "        ax[i, j].imshow(first_zero.reshape(28, 28), cmap=\"grey\", alpha=.3)\n",
    "        ax[i, j].set_axis_off()\n",
    "plt.savefig(\"images/intended_for_paper/rise_n_masks.png\")\n",
    "\"\"\""
   ],
   "id": "2187058762a394b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfig, ax = plt.subplots(2, 3)\\nnum_of_masks=[[10**1, 10**2, 10**3], [10**4, 10**5, 10**6]]\\nfirst_zero_input = first_zero.numpy().reshape(1, 28, 28).astype(np.float32)\\nfor i in range(2):\\n    current_masks = num_of_masks[0] if i == 0 else num_of_masks[1]\\n    for j in range(3):\\n        saliency_map_rise = dianna.explain_image(model_path, first_zero_input, method=\"RISE\", labels=[0], n_masks=current_masks[j], axis_labels=axis_labels, p_keep=0.5)\\n        ax[i, j].set_title(f\"Masks = {current_masks[j]}\")\\n        ax[i, j].imshow(saliency_map_rise.reshape(28, 28))\\n        ax[i, j].imshow(first_zero.reshape(28, 28), cmap=\"grey\", alpha=.3)\\n        ax[i, j].set_axis_off()\\nplt.savefig(\"images/intended_for_paper/rise_n_masks.png\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "When generating the pictures, we are also interested in showcasing the DAUC metric. Unfortunately no package was found, that implements the DAUC directly, which is why we do that ourselves. \n",
    "We can delete the corresponding by selecting the maxium values in the saliency map. We will gradually take the most yellow pixels, then replace them, run the model, to get the new confidence. We also want to draw \n",
    "the deleted regions in the picture output for reference."
   ],
   "id": "8b8db23332561f07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:33:09.252787Z",
     "start_time": "2024-06-28T10:33:09.227732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We will use the inferred session, to generate the probability outputs for the deletion metric. Dianna abstracts away the instantiation of the session, so we will have to that ourselves. This also allows us\n",
    "# to negate the log-softmax output nodes, by using the exponential function before we output the probabilities themselves\n",
    "session = ort.InferenceSession(model_path)\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "predict = lambda input_for_prediction: session.run([output_name], {input_name: input_for_prediction})"
   ],
   "id": "1122e3d132c31169",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:33:09.257537Z",
     "start_time": "2024-06-28T10:33:09.254416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_rise_saliency_map_for_inputs_with_lower_dauc_than_100_and_save_as_image(image_deleted_areas, index, original_zero):\n",
    "    image_deleted_areas = image_deleted_areas.reshape(1, 1, 28, 28)\n",
    "    prediction_deleted = np.exp(predict(image_deleted_areas))[0, 0, 0]\n",
    "    prediction_normal = np.exp(predict(original_zero.reshape(1, 1, 28, 28)))[0, 0, 0]\n",
    "    image_deleted_saliency_map_rise = dianna.explain_image(model_path, image_deleted_areas.reshape(1, 28, 28), method=\"RISE\", labels=[0], n_masks=5*10**4, axis_labels=axis_labels, p_keep=0.5)\n",
    "    fix, ax = plt.subplots(1, 2)\n",
    "    ax[0].set_title(f\"Conf.: {prediction_normal:2f}\")\n",
    "    ax[0].imshow(original_zero.reshape(28, 28), cmap=\"grey\")\n",
    "    ax[0].set_axis_off()\n",
    "    \n",
    "    ax[1].set_title(f\"Conf.: {prediction_deleted:.2f}\")\n",
    "    ax[1].imshow(image_deleted_saliency_map_rise.reshape(28, 28))\n",
    "    ax[1].imshow(image_deleted_areas.reshape(28, 28), cmap=\"grey\", alpha=.3)\n",
    "    ax[1].set_axis_off()\n",
    "    plt.savefig(f\"images/saliency_maps_for_hypothesis_testing/{index}_zero_deleted_areas.png\")\n",
    "    plt.close()"
   ],
   "id": "2d7dd9bdd35e8b9e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:33:10.158007Z",
     "start_time": "2024-06-28T10:33:09.260105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.integrate import trapezoid\n",
    "\n",
    "def calc_deletion_metric_and_return_image_with_deleted_areas_and_dauc(original_input, saliency_map):\n",
    "    saliency_map_copy = np.copy(saliency_map).reshape(28, 28)\n",
    "    original_input_copy = np.copy(original_input).reshape(28, 28)\n",
    "    \n",
    "    pixels_to_delete = 150\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    for _ in range(pixels_to_delete):\n",
    "        min_value_to_replace_max_with = np.min(saliency_map_copy)\n",
    "        saliency_map_max_value_x_index, saliency_map_max_value_y_index = np.unravel_index(np.argmax(saliency_map_copy), shape=(28, 28))\n",
    "        saliency_map_copy[saliency_map_max_value_x_index][saliency_map_max_value_y_index] = min_value_to_replace_max_with\n",
    "        original_input_copy[saliency_map_max_value_x_index][saliency_map_max_value_y_index] = 0\n",
    "        \n",
    "        predicted_output = np.exp(predict(original_input_copy.reshape(1, 1, 28, 28)))[0, 0, 0] # slicing to only get the output prob for the zero class\n",
    "        \n",
    "        outputs.append(predicted_output)\n",
    "        \n",
    "    outputs = np.asarray(outputs)\n",
    "    deleted_area_under_curve = trapezoid(y=outputs, x=list(range(pixels_to_delete)))\n",
    "    \n",
    "    return original_input_copy, deleted_area_under_curve"
   ],
   "id": "1ab3031bd8ae1f7b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:33:10.163706Z",
     "start_time": "2024-06-28T10:33:10.158808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_heatmaps_side_by_side_with_original_as_png_file(index_as_filename:int, original_zero, \n",
    "                                                         rise_map, image_deleted_rise, dauc_rise, \n",
    "                                                         lime_map, image_deleted_lime, dauc_lime,\n",
    "                                                         shap_map, image_deleted_shap, dauc_shap):\n",
    "    original_zero = original_zero.reshape(28, 28) # Reshap for display\n",
    "    rise_map = rise_map.reshape(28, 28)\n",
    "    image_deleted_rise = image_deleted_rise.reshape(28, 28)\n",
    "    lime_map = lime_map.reshape(28, 28)\n",
    "    image_deleted_lime = image_deleted_lime.reshape(28, 28)\n",
    "    shap_map = shap_map.reshape(28, 28)\n",
    "    image_deleted_shap = image_deleted_shap.reshape(28, 28)\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 4, figsize=(7, 4))\n",
    "    ax[0, 0].set_title(\"Original Data\")\n",
    "    ax[0, 0].imshow(original_zero, cmap=\"grey\")\n",
    "    ax[0, 0].set_axis_off()\n",
    "    \n",
    "    ax[0, 1].set_title(\"RISE\")\n",
    "    ax[0, 1].imshow(rise_map)\n",
    "    ax[0, 1].imshow(original_zero, alpha=.3)\n",
    "    ax[0, 1].set_axis_off()\n",
    "    \n",
    "    ax[1, 0].axis('off')\n",
    "    \n",
    "    ax[1, 1].imshow(image_deleted_rise, cmap=\"grey\")\n",
    "    ax[1, 1].set_axis_off()\n",
    "    ax[1, 1].set_title(f\"DAUC = {dauc_rise:.2f}\")\n",
    "    \n",
    "    ax[0, 2].set_title(\"LIME\")\n",
    "    ax[0, 2].imshow(lime_map)\n",
    "    ax[0, 2].imshow(original_zero, alpha=.3)\n",
    "    ax[0, 2].set_axis_off()\n",
    "    \n",
    "    ax[1, 2].imshow(image_deleted_lime, cmap=\"grey\")\n",
    "    ax[1, 2].set_title(f\"DAUC = {dauc_lime:.2f}\")\n",
    "    ax[1, 2].set_axis_off()\n",
    "    \n",
    "    ax[0, 3].set_title(\"KernelSHAP\")\n",
    "    ax[0, 3].imshow(shap_map)\n",
    "    ax[0, 3].imshow(original_zero, alpha=.3)\n",
    "    ax[0, 3].set_axis_off()\n",
    "    \n",
    "    ax[1, 3].imshow(image_deleted_shap, cmap=\"grey\")\n",
    "    ax[1, 3].set_title(f\"DAUC = {dauc_shap:.2f}\")\n",
    "    ax[1, 3].set_axis_off()\n",
    "    \n",
    "    plt.savefig(f\"images/saliency_maps/{index_as_filename + 1}_zero.png\")\n",
    "    plt.close()\n",
    "    #plt.show()"
   ],
   "id": "d0d4797f6b641898",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:33:10.168077Z",
     "start_time": "2024-06-28T10:33:10.164358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "normalize_input_img = lambda img: (img / 255).astype(np.float32)\n",
    "\n",
    "def run_all_explainibility_methods_on_first_k_inputs_and_generate_mean_saliency_maps(k_first_samples: int):\n",
    "    daucs_rise, daucs_lime, daucs_shap = [], [], []\n",
    "    for i in range(k_first_samples):\n",
    "            zero = return_training_tensors_from_target_class(0)[i]\n",
    "            zero = zero.numpy().reshape(1, 28, 28).astype(np.float32) # Reshape to right format expected for the input\n",
    "            \n",
    "            # RISE\n",
    "            saliency_map_rise = dianna.explain_image(model_path, zero, method=\"RISE\", labels=[0], n_masks=10**4, axis_labels=axis_labels, p_keep=0.5)\n",
    "            image_deleted_ares_rise, dauc_rise = calc_deletion_metric_and_return_image_with_deleted_areas_and_dauc(zero, saliency_map_rise)\n",
    "            daucs_rise.append(dauc_rise)\n",
    "            \n",
    "            if dauc_rise <= 100:\n",
    "                calc_rise_saliency_map_for_inputs_with_lower_dauc_than_100_and_save_as_image(image_deleted_ares_rise, i, zero)\n",
    "            \n",
    "            # LIME\n",
    "            saliency_map_lime = dianna.explain_image(model_path, zero, method=\"LIME\", labels=[0, 1], axis_labels=axis_labels, num_features=100, num_samples=10000, preprocess_function=normalize_input_img)[0]\n",
    "            image_deleted_areas_lime, dauc_lime = calc_deletion_metric_and_return_image_with_deleted_areas_and_dauc(zero, saliency_map_lime)\n",
    "            daucs_lime.append(dauc_lime)\n",
    "            \n",
    "            # SHAP\n",
    "            saliency_map_shap = dianna.explain_image(model_path, zero, method=\"KernelSHAP\", axis_labels=axis_labels, labels=[0], background=0, nsamples=10000, n_segments=200)[0]\n",
    "            image_deleted_ares_shap, dauc_shap = calc_deletion_metric_and_return_image_with_deleted_areas_and_dauc(zero, saliency_map_shap)\n",
    "            daucs_shap.append(dauc_shap)\n",
    "        \n",
    "            save_heatmaps_side_by_side_with_original_as_png_file(i, zero, \n",
    "                                                                 saliency_map_rise, image_deleted_ares_rise, dauc_rise,\n",
    "                                                                 saliency_map_lime, image_deleted_areas_lime, dauc_lime,\n",
    "                                                                 saliency_map_shap, image_deleted_ares_shap, dauc_shap)\n",
    "    return daucs_rise, daucs_lime, daucs_shap    "
   ],
   "id": "3dc126f7197dba07",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:33:40.833594Z",
     "start_time": "2024-06-28T10:33:10.168711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "daucs_rise, daucs_lime, daucs_shap = run_all_explainibility_methods_on_first_k_inputs_and_generate_mean_saliency_maps(1) # The one is just for showcase, for the 100 images, the parameter was a 100 of course"
   ],
   "id": "88a7c2932af55b39",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 12:33:36.860118: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:933] Skipping loop optimization for Merge node with control input: assert_equal_1/Assert/AssertGuard/branch_executed/_9\n",
      "2024-06-28 12:33:36.988782: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:933] Skipping loop optimization for Merge node with control input: assert_equal_1/Assert/AssertGuard/branch_executed/_9\n",
      "2024-06-28 12:33:39.811934: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:933] Skipping loop optimization for Merge node with control input: assert_equal_1/Assert/AssertGuard/branch_executed/_9\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:33:40.855747Z",
     "start_time": "2024-06-28T10:33:40.834963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "mean_dauc_rise = np.sum(daucs_rise) / 100 # The dividing number has to be eqal to the k_first_samples parameter, the previous parameter was 100\n",
    "mean_dauc_lime = np.sum(daucs_lime) / 100\n",
    "mean_daus_shap = np.sum(daucs_shap) / 100\n",
    "\"\"\""
   ],
   "id": "60ef4d0da03150b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmean_dauc_rise = np.sum(daucs_rise) / 100 # The dividing number has to be eqal to the k_first_samples parameter, the previous parameter was 100\\nmean_dauc_lime = np.sum(daucs_lime) / 100\\nmean_daus_shap = np.sum(daucs_shap) / 100\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:33:40.865017Z",
     "start_time": "2024-06-28T10:33:40.857155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "print(f\"Mean DAUC of RISE = {mean_dauc_rise}\")\n",
    "print(f\"Mean DAUC of LIME = {mean_dauc_lime}\")\n",
    "print(f\"Mean DAUC of SHAP = {mean_daus_shap}\")\n",
    "\n",
    "# Output\n",
    "Mean DAUC of RISE = 112.41859805512533\n",
    "Mean DAUC of LIME = 147.35999051243067\n",
    "Mean DAUC of SHAP = 148.9337806534767\n",
    "\"\"\""
   ],
   "id": "e2fa99f5ff54d43b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(f\"Mean DAUC of RISE = {mean_dauc_rise}\")\\nprint(f\"Mean DAUC of LIME = {mean_dauc_lime}\")\\nprint(f\"Mean DAUC of SHAP = {mean_daus_shap}\")\\n\\nMean DAUC of RISE = 112.41859805512533\\nMean DAUC of LIME = 147.35999051243067\\nMean DAUC of SHAP = 148.9337806534767\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "According to the mean dauc, the RISE method performs better more often. We will focus on the saliency maps generated by rise, to derive features of a good explanation, for the zero classification.\n",
    "Generally, the highlighted regions of RISE contain both side of the zero, with visually the same importance. However, there seem to be some zeros, where the sides dont seem to be equally important. \n",
    "We will create a list of indices, to rerun RISE with those zeros, but with a higher number of masks than 10^4. If both sides then are equally important, the random mask generation is at fault. But if it stays \n",
    "the same, i.e the sides are still note equally important, it is more likely, that we have to different groups of zeros at hand."
   ],
   "id": "6c2bde02e87aa384"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:33:40.881467Z",
     "start_time": "2024-06-28T10:33:40.877707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# These numbers were derived from the saliency_maps image folder, where the sides dont seem to be equally important\n",
    "list_of_indices = [\n",
    "    7, 8, 10, 11, 14, 26, 29, 31, 39, 40, 44, 47, 48, 49, 51, 53, 54, 59, 66, 68, 69, 71, 72, 73, 74, 75, 77, 78, 81, 82, 83, 85, 86, 88, 90, 93, 94, 95, 96, 97, 99\n",
    "]"
   ],
   "id": "e95c614aa20f9746",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:35:38.848352Z",
     "start_time": "2024-06-28T10:35:38.845583Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(list_of_indices))",
   "id": "fecc2e15e0549c17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T11:48:47.916928Z",
     "start_time": "2024-06-28T10:57:39.868606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for index in list_of_indices:\n",
    "    zero = return_training_tensors_from_target_class(0)[index - 1]\n",
    "    zero = zero.numpy().reshape(1, 28, 28).astype(np.float32)\n",
    "    saliency_map_rise = dianna.explain_image(model_path, zero, method=\"RISE\", labels=[0], n_masks=5*10**4, axis_labels=axis_labels, p_keep=0.5)\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.title(\"RISE\")\n",
    "    plt.imshow(saliency_map_rise.reshape(28, 28))\n",
    "    plt.imshow(zero.reshape(28, 28), alpha=.3, cmap=\"grey\")\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f\"images/rise_asymmetrical_tests/{index}_rise_asymmetrical_zero_test.png\")\n",
    "    plt.close()"
   ],
   "id": "dba265a5f5037b76",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explaining: 100%|██████████| 50000/50000 [01:09<00:00, 715.03it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:10<00:00, 713.73it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:10<00:00, 712.08it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:10<00:00, 713.43it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:10<00:00, 704.76it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:10<00:00, 711.97it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:11<00:00, 699.26it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:10<00:00, 709.18it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:10<00:00, 710.40it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:10<00:00, 711.31it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:09<00:00, 714.83it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:10<00:00, 711.56it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:10<00:00, 712.37it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:10<00:00, 705.35it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:10<00:00, 706.52it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:11<00:00, 703.93it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:10<00:00, 710.20it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:10<00:00, 708.32it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:11<00:00, 694.60it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:10<00:00, 707.16it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:12<00:00, 692.29it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:12<00:00, 689.63it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:13<00:00, 684.02it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:13<00:00, 682.71it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:14<00:00, 674.69it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:09<00:00, 716.39it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:05<00:00, 765.56it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:06<00:00, 749.79it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:16<00:00, 656.54it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:15<00:00, 659.16it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:16<00:00, 651.27it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:16<00:00, 653.64it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:15<00:00, 662.81it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:15<00:00, 661.54it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:15<00:00, 660.43it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:15<00:00, 666.00it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:14<00:00, 670.21it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:14<00:00, 668.97it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:15<00:00, 663.78it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:14<00:00, 667.64it/s]\n",
      "Explaining: 100%|██████████| 50000/50000 [01:15<00:00, 664.81it/s]\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
